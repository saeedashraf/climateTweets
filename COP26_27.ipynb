{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.11.0 tenacity-8.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=0.25->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from wordcloud) (1.23.4)\n",
      "Requirement already satisfied: matplotlib in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from wordcloud) (3.6.2)\n",
      "Requirement already satisfied: pillow in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from wordcloud) (9.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.3.2\n",
      "  Using cached scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from scikit-learn) (1.23.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: scipy, threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.0 scipy-1.9.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLyJ4zsN-KHG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "elXe-Ajk-2w5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89K_Z2F7-Sv_"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/ColabUZH/twitter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x9jDn9CM_06D"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7k_Fz6XmfAl5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_6WImpnswA9w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (2.3.8)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (44.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (7.4.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (0.7.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy) (1.23.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gH1XgNu1wTqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: requests in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[K     |████████████████████████████████| 772 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Installing collected packages: tokenizers, filelock, pyyaml, huggingface-hub, regex, transformers\n",
      "Successfully installed filelock-3.8.2 huggingface-hub-0.11.1 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Hx-s_l_bwcmk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_lg==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from en_core_web_lg==2.3.1) (2.3.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.8)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.23.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.10.1)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (44.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.7)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.26.12)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.13.0%2Bcpu-cp38-cp38-linux_x86_64.whl (198.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 198.5 MB 188 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.14.0%2Bcpu-cp38-cp38-linux_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.13.0%2Bcpu-cp38-cp38-linux_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: requests in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.13.0+cpu torchaudio-0.13.0+cpu torchvision-0.14.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/saeidashraf/Saeidproj/nlp_uzh_geo/venv_geoparser/lib/python3.8/site-packages (from gensim) (1.9.3)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.2.0 smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Mjnee6vMvvVJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/saeidashraf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/saeidashraf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/saeidashraf/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/saeidashraf/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk.corpus\n",
    "from nltk.probability import FreqDist\n",
    "import spacy\n",
    "import string\n",
    "import en_core_web_lg\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader,RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, AdamW, get_linear_schedule_with_warmup, TrainingArguments, BeamScorer, Trainer\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "K1zjmTQqD5n-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "print(type(STOPWORDS))\n",
    "print(len(STOPWORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VGeczceTRP8r"
   },
   "outputs": [],
   "source": [
    "#STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FPJj_BHByZ5w"
   },
   "outputs": [],
   "source": [
    "common = [\"a\",\"able\",\"about\",\"across\",\"after\",\"all\",\"almost\",\"also\",\"am\",\"among\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\n",
    "          \"been\",\"but\",\"by\",\"can\",\"cannot\",\"could\",\"dear\",\"did\",\"do\",\"does\",\"either\",\"else\",\"ever\",\"every\",\"for\",\"from\",\"get\",\"got\",\n",
    "          \"had\",\"has\",\"have\",\"he\",\"her\",\"hers\",\"him\",\"his\",\"how\",\"however\",\"i\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"least\",\"let\",\n",
    "          \"like\",\"likely\",\"may\",\"me\",\"might\",\"most\",\"must\",\"my\",\"neither\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"often\",\"on\",\"only\",\"or\",\"other\",\n",
    "          \"our\",\"own\",\"rather\",\"said\",\"say\",\"says\",\"she\",\"should\",\"since\",\"so\",\"some\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\n",
    "          \"these\",\"they\",\"this\",\"tis\",\"to\",\"too\",\"twas\",\"us\",\"wants\",\"was\",\"we\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\n",
    "          \"why\",\"will\",\"with\",\"would\",\"yet\",\"you\",\"your\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiyU6zzcek_b"
   },
   "outputs": [],
   "source": [
    "def washing_machine(text, lemmatize=True):\n",
    "#     print(\"===============================\")\n",
    "#     print(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop = stopwords.words('english')\n",
    "#     print(stop)\n",
    "    ready = stop+common\n",
    "#     print(ready)\n",
    "    text= text.lower()\n",
    "#     print(text)\n",
    "#     print(\"=============================================================\")\n",
    "    text = re.sub(r\"<sup>(.*)</sup>|<sub>(.*)</sub>|&lt;|&gt;|%|\\([^()]*\\)|(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?|\\d+\", \"\", text)\n",
    "#     print(text)\n",
    "    if lemmatize:\n",
    "        text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in (ready)])\n",
    "    else:\n",
    "        text = \" \".join([stemmer.stem(word) for word in text.split() if word not in (ready)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PF31adm0ekxu"
   },
   "outputs": [],
   "source": [
    "context_common = ['dtype','object'] \n",
    "STOPWORDS.update(common)\n",
    "STOPWORDS.update(context_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYcwL7p3R_78"
   },
   "outputs": [],
   "source": [
    "print(type(STOPWORDS))\n",
    "print(len(STOPWORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0QObAd3xkD1"
   },
   "source": [
    "\n",
    "# COP26 4 months prior to COP26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9--bDJXHDXaK"
   },
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "794fqx86_0ul"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26 = pd.read_csv('df_20210621_1021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1AwhgWA_0rz"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CY98cfsKGWxH"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDgAsh6HGWsV"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMjABzRWGWoG"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHlDhJaCN6kb"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26['author_followers'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6650ZFQO_vf"
   },
   "outputs": [],
   "source": [
    "filt_1 = df21_old_COP26['author_followers'] >= df21_old_COP26['author_followers'].quantile(0.5)\n",
    "filt_2 = df21_old_COP26['retweets'] >= df21_old_COP26['retweets'].quantile(0.5)\n",
    "filt_3 = df21_old_COP26['replies'] >= df21_old_COP26['replies'].quantile(0.5)\n",
    "filt_4 = df21_old_COP26['likes'] >= df21_old_COP26['likes'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hcsa6zwXGWbQ"
   },
   "outputs": [],
   "source": [
    "filt_1 = (df21_old_COP26['author_followers'] >= df21_old_COP26['author_followers'].quantile(0.5)) | \\\n",
    "          (df21_old_COP26['retweets'] >= df21_old_COP26['retweets'].quantile(0.5)) | \\\n",
    "          (df21_old_COP26['replies'] >= df21_old_COP26['replies'].quantile(0.5)) | \\\n",
    "          (df21_old_COP26['likes'] >= df21_old_COP26['likes'].quantile(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haJKR1pnPz_Y"
   },
   "outputs": [],
   "source": [
    "df_ = df21_old_COP26[filt_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itSOsY_HPz8a"
   },
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlHApJNAPz5A"
   },
   "outputs": [],
   "source": [
    "df21_old_COP26.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnp9jTRVPz2B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frA1hLZZPzzF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7XPbwaSPzwX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VmaJgp3Pzsw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cy5mXKQPzpx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUJoSrahPzmU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHTIzaE1_zob"
   },
   "outputs": [],
   "source": [
    "all_text_1 = ''\n",
    "for i in range (len(df21_old_COP26)):\n",
    "    all_text_1 +=  str(df21_old_COP26['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiQ8m1mWxVAM"
   },
   "outputs": [],
   "source": [
    "with open('df21_old_COP26.txt', 'a') as file:\n",
    "    file.write(all_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZc4G0aYRISH"
   },
   "outputs": [],
   "source": [
    "!pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjdbjiMpVZG6"
   },
   "outputs": [],
   "source": [
    "all_text_1_preprocess = washing_machine(all_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pjl4rmzADiN9"
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width= 3000, height = 2000,\n",
    "                      background_color='Salmon', \n",
    "                      max_words=3000,\n",
    "                      stopwords = STOPWORDS,\n",
    "                      colormap='Pastel1', \n",
    "                      collocations=False,\n",
    "                       repeat=False\n",
    "                         ).generate(all_text_1_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-TA10X2Shz8"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize = (30,20))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p05tNx4SotB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UFaOCCuyTcu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASJ9csOix_cB"
   },
   "source": [
    "\n",
    "\n",
    "# COP26 1 week befor to 1 week after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfHEejem-Sjq"
   },
   "outputs": [],
   "source": [
    "df21_new_COP26 = pd.read_csv('df_20211022_1121.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrUFqZCR-UE0"
   },
   "outputs": [],
   "source": [
    "df21_new_COP26.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h16_gU1j-UBf"
   },
   "outputs": [],
   "source": [
    "df21_new_COP26.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJbadko3-T7g"
   },
   "outputs": [],
   "source": [
    "df21_new_COP26.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7Wz4j1l-Tz4"
   },
   "outputs": [],
   "source": [
    "df21_new_COP26.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrJYD-zg_0_p"
   },
   "outputs": [],
   "source": [
    "all_text_2 = ''\n",
    "for i in range (len(df21_new_COP26)):\n",
    "    all_text_2 +=  str(df21_new_COP26['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0UaDHZyWxp5"
   },
   "outputs": [],
   "source": [
    "with open('df21_new_COP26.txt', 'a') as file:\n",
    "    file.write(all_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Tqzjh8mWxiX"
   },
   "outputs": [],
   "source": [
    "all_text_2_preprocessed = washing_machine(all_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_PaiWDTXDRm"
   },
   "outputs": [],
   "source": [
    "wordcloud_2 = WordCloud(width= 3000, height = 2000,\n",
    "                      background_color='Salmon',\n",
    "                      stopwords = STOPWORDS,\n",
    "                      colormap='Pastel1', \n",
    "                      collocations=False,\n",
    "                       repeat=False\n",
    "                         ).generate(all_text_2_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-LEOIhWXDKG"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize = (30,20))\n",
    "plt.imshow(wordcloud_2, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOn4DvcK7ixq"
   },
   "outputs": [],
   "source": [
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afHE78bE_0xY"
   },
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width= 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(all_text_2_preprocessed)\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kATgIZO7pVg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBhqU6xc7pL4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S25hQHRuyhGe"
   },
   "source": [
    "# COP27 4 months prior to COP27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USSfj6ETng8V"
   },
   "outputs": [],
   "source": [
    "df22_old_COP27 = pd.read_csv('df_20220627_1026_COP27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxkRSpLlneVo"
   },
   "outputs": [],
   "source": [
    "df22_old_COP27.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFb_SESUp6gl"
   },
   "outputs": [],
   "source": [
    "all_text_3 = ''\n",
    "for i in range (len(df22_old_COP27)):\n",
    "    all_text_3 +=  str(df22_old_COP27['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOgnTFFpbjtE"
   },
   "outputs": [],
   "source": [
    "with open('df22_old_COP27.txt', 'a') as file:\n",
    "    file.write(all_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK1MhY2objWs"
   },
   "outputs": [],
   "source": [
    "all_text_3_preprocessed = washing_machine(all_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPugZHXHbjO2"
   },
   "outputs": [],
   "source": [
    "wordcloud_3 = WordCloud(width= 3000, height = 2000,\n",
    "                      background_color='Salmon', \n",
    "                      max_words=3000,\n",
    "                      stopwords = STOPWORDS,\n",
    "                      colormap='Pastel1', \n",
    "                      collocations=False,\n",
    "                       repeat=False\n",
    "                         ).generate(all_text_3_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KAjRk85bjHk"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize = (30,20))\n",
    "plt.imshow(wordcloud_3, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hl5k7HuIbi_j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td9AntcHp6YD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jcjR6b0yqSw"
   },
   "source": [
    "# COP27 1 week before to 1 week after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEZ-aon3p6P7"
   },
   "outputs": [],
   "source": [
    "df22_new_COP27 = pd.read_csv('df_20221027_1126_COP27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IS0hHLnKrX8Q"
   },
   "outputs": [],
   "source": [
    "df22_new_COP27.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRMTTYUNrXlw"
   },
   "outputs": [],
   "source": [
    "all_text_4 = ''\n",
    "for i in range (len(df22_new_COP27)):\n",
    "    all_text_4 +=  str(df22_new_COP27['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vm504NTcEjG"
   },
   "outputs": [],
   "source": [
    "with open('df22_new_COP27.txt', 'a') as file:\n",
    "    file.write(all_text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6o7EchF-cEZG"
   },
   "outputs": [],
   "source": [
    "all_text_4_preprocessed = washing_machine(all_text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTrJVnJYcEWO"
   },
   "outputs": [],
   "source": [
    "wordcloud_4 = WordCloud(width= 3000, height = 2000,\n",
    "                      background_color='Salmon', \n",
    "                      max_words=3000,\n",
    "                      stopwords = STOPWORDS,\n",
    "                      colormap='Pastel1', \n",
    "                      collocations=False,\n",
    "                       repeat=False\n",
    "                         ).generate(all_text_4_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Et5DMvKVcET3"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize = (30,20))\n",
    "plt.imshow(wordcloud_4, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjlAGYchcEQy"
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WlJhvEqcEJF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMJf/6VRPLscpox/5hYi0ip",
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
